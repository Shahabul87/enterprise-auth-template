# Prometheus Alert Rules for Enterprise Auth Template
# These rules define when to trigger alerts based on metrics

groups:
  - name: api_alerts
    interval: 30s
    rules:
      # High request latency
      - alert: HighRequestLatency
        expr: |
          histogram_quantile(0.95, 
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, method, endpoint)
          ) > 1
        for: 5m
        labels:
          severity: warning
          component: api
        annotations:
          summary: "High request latency detected"
          description: "95th percentile latency for {{ $labels.method }} {{ $labels.endpoint }} is {{ $value }}s (threshold: 1s)"

      # Very high request latency
      - alert: VeryHighRequestLatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, method, endpoint)
          ) > 3
        for: 2m
        labels:
          severity: critical
          component: api
        annotations:
          summary: "Critical request latency detected"
          description: "95th percentile latency for {{ $labels.method }} {{ $labels.endpoint }} is {{ $value }}s (threshold: 3s)"

      # High error rate
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status_code=~"5.."}[5m])) by (method, endpoint)
          /
          sum(rate(http_requests_total[5m])) by (method, endpoint)
          > 0.05
        for: 5m
        labels:
          severity: warning
          component: api
        annotations:
          summary: "High error rate detected"
          description: "Error rate for {{ $labels.method }} {{ $labels.endpoint }} is {{ $value | humanizePercentage }} (threshold: 5%)"

      # API down
      - alert: APIDown
        expr: up{job="backend-api"} == 0
        for: 1m
        labels:
          severity: critical
          component: api
        annotations:
          summary: "API is down"
          description: "The backend API has been down for more than 1 minute"

  - name: database_alerts
    interval: 30s
    rules:
      # Slow database queries
      - alert: SlowDatabaseQueries
        expr: |
          histogram_quantile(0.95,
            sum(rate(database_query_duration_seconds_bucket[5m])) by (le, operation, table)
          ) > 0.5
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "Slow database queries detected"
          description: "95th percentile query time for {{ $labels.operation }} on {{ $labels.table }} is {{ $value }}s (threshold: 0.5s)"

      # Database connection pool exhaustion
      - alert: DatabaseConnectionPoolExhaustion
        expr: |
          database_connection_pool_size{pool_type="idle"} 
          / 
          database_connection_pool_size{pool_type="total"} 
          < 0.1
        for: 3m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "Database connection pool near exhaustion"
          description: "Only {{ $value | humanizePercentage }} of connections are idle"

      # Database down
      - alert: DatabaseDown
        expr: up{job="postgresql"} == 0
        for: 1m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "Database is down"
          description: "PostgreSQL database has been down for more than 1 minute"

  - name: authentication_alerts
    interval: 30s
    rules:
      # High failed login rate
      - alert: HighFailedLoginRate
        expr: |
          sum(rate(user_login_attempts_total{status="failure"}[5m]))
          /
          sum(rate(user_login_attempts_total[5m]))
          > 0.3
        for: 5m
        labels:
          severity: warning
          component: authentication
        annotations:
          summary: "High failed login rate detected"
          description: "Failed login rate is {{ $value | humanizePercentage }} (threshold: 30%)"

      # Potential brute force attack
      - alert: PotentialBruteForceAttack
        expr: |
          sum(rate(user_login_attempts_total{status="failure"}[1m])) by (client_ip)
          > 10
        for: 2m
        labels:
          severity: critical
          component: security
        annotations:
          summary: "Potential brute force attack detected"
          description: "More than 10 failed login attempts per minute from {{ $labels.client_ip }}"

      # Registration spike
      - alert: RegistrationSpike
        expr: |
          sum(rate(user_registrations_total[5m])) 
          > 
          3 * avg_over_time(sum(rate(user_registrations_total[5m]))[1h:5m])
        for: 10m
        labels:
          severity: info
          component: authentication
        annotations:
          summary: "Unusual registration spike detected"
          description: "Registration rate is 3x higher than the hourly average"

  - name: cache_alerts
    interval: 30s
    rules:
      # Low cache hit rate
      - alert: LowCacheHitRate
        expr: |
          sum(rate(cache_hits_total[5m])) by (cache_type)
          /
          (sum(rate(cache_hits_total[5m])) by (cache_type) + sum(rate(cache_misses_total[5m])) by (cache_type))
          < 0.7
        for: 10m
        labels:
          severity: warning
          component: cache
        annotations:
          summary: "Low cache hit rate"
          description: "Cache hit rate for {{ $labels.cache_type }} is {{ $value | humanizePercentage }} (threshold: 70%)"

      # Redis down
      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
          component: cache
        annotations:
          summary: "Redis is down"
          description: "Redis cache has been down for more than 1 minute"

  - name: resource_alerts
    interval: 30s
    rules:
      # High memory usage
      - alert: HighMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.9
        for: 5m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value | humanizePercentage }} (threshold: 90%)"

      # High CPU usage
      - alert: HighCPUUsage
        expr: |
          100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value }}% (threshold: 80%)"

      # Disk space low
      - alert: DiskSpaceLow
        expr: |
          (1 - (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"})) > 0.85
        for: 5m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "Disk space running low"
          description: "Disk usage is {{ $value | humanizePercentage }} (threshold: 85%)"

  - name: business_alerts
    interval: 1m
    rules:
      # No new users registered
      - alert: NoNewUsersRegistered
        expr: |
          sum(increase(user_registrations_total[1h])) == 0
        for: 2h
        labels:
          severity: info
          component: business
        annotations:
          summary: "No new user registrations"
          description: "No new users have registered in the last 2 hours"

      # Unusual activity pattern
      - alert: UnusualActivityPattern
        expr: |
          abs(
            sum(rate(http_requests_total[5m])) 
            - 
            avg_over_time(sum(rate(http_requests_total[5m]))[1h:5m])
          ) 
          > 
          3 * stddev_over_time(sum(rate(http_requests_total[5m]))[1h:5m])
        for: 15m
        labels:
          severity: info
          component: business
        annotations:
          summary: "Unusual activity pattern detected"
          description: "Request rate deviates significantly from normal pattern"